{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations and Insights "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies and Setup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "\n",
    "# Study data files_\n",
    "mouse_metadata_path = \"data_files/Mouse_metadata.csv\"\n",
    "study_results_path = \"data_files/Study_results.csv\"\n",
    "\n",
    "# Read the mouse data and the study results\n",
    "mouse_metadata = pd.read_csv(mouse_metadata_path)\n",
    "study_results = pd.read_csv(study_results_path)\n",
    "\n",
    "# Combine the data into a single dataset (merge with an inner join on mouse ID)\n",
    "main_study_df =  pd.merge(mouse_metadata,study_results,on=\"Gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>RegionID</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>RegionType</th>\n",
       "      <th>2010-01</th>\n",
       "      <th>2010-02</th>\n",
       "      <th>2010-03</th>\n",
       "      <th>2010-04</th>\n",
       "      <th>2010-05</th>\n",
       "      <th>2010-06</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-04</th>\n",
       "      <th>2019-05</th>\n",
       "      <th>2019-06</th>\n",
       "      <th>2019-07</th>\n",
       "      <th>2019-08</th>\n",
       "      <th>2019-09</th>\n",
       "      <th>2019-10</th>\n",
       "      <th>2019-11</th>\n",
       "      <th>2019-12</th>\n",
       "      <th>2020-01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>102001</td>\n",
       "      <td>United States</td>\n",
       "      <td>Country</td>\n",
       "      <td>139.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>...</td>\n",
       "      <td>72.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>394913</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Msa</td>\n",
       "      <td>199.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>139.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>753899</td>\n",
       "      <td>Los Angeles-Long Beach-Anaheim, CA</td>\n",
       "      <td>Msa</td>\n",
       "      <td>123.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>394463</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Msa</td>\n",
       "      <td>184.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>189.5</td>\n",
       "      <td>172.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>...</td>\n",
       "      <td>77.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>394514</td>\n",
       "      <td>Dallas-Fort Worth, TX</td>\n",
       "      <td>Msa</td>\n",
       "      <td>117.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>655</td>\n",
       "      <td>394578</td>\n",
       "      <td>Evanston, WY</td>\n",
       "      <td>Msa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>121.5</td>\n",
       "      <td>114.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>656</td>\n",
       "      <td>395004</td>\n",
       "      <td>Prineville, OR</td>\n",
       "      <td>Msa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>93.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>657</td>\n",
       "      <td>786263</td>\n",
       "      <td>Ruidoso, NM</td>\n",
       "      <td>Msa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>113.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>132.5</td>\n",
       "      <td>107.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>658</td>\n",
       "      <td>394805</td>\n",
       "      <td>Los Alamos, NM</td>\n",
       "      <td>Msa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>46.5</td>\n",
       "      <td>49.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>659</td>\n",
       "      <td>395111</td>\n",
       "      <td>Spencer, IA</td>\n",
       "      <td>Msa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>115.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>64.5</td>\n",
       "      <td>61.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>76.5</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>660 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SizeRank  RegionID                          RegionName RegionType  \\\n",
       "0           0    102001                       United States    Country   \n",
       "1           1    394913                        New York, NY        Msa   \n",
       "2           2    753899  Los Angeles-Long Beach-Anaheim, CA        Msa   \n",
       "3           3    394463                         Chicago, IL        Msa   \n",
       "4           4    394514               Dallas-Fort Worth, TX        Msa   \n",
       "..        ...       ...                                 ...        ...   \n",
       "655       655    394578                        Evanston, WY        Msa   \n",
       "656       656    395004                      Prineville, OR        Msa   \n",
       "657       657    786263                         Ruidoso, NM        Msa   \n",
       "658       658    394805                      Los Alamos, NM        Msa   \n",
       "659       659    395111                         Spencer, IA        Msa   \n",
       "\n",
       "     2010-01  2010-02  2010-03  2010-04  2010-05  2010-06  ...  2019-04  \\\n",
       "0      139.0    142.0    143.0    140.0    119.0    111.0  ...     72.0   \n",
       "1      199.0    202.0    201.0    200.0    208.0    160.0  ...    139.0   \n",
       "2      123.0    137.0    122.0    101.0     84.0     93.0  ...     64.0   \n",
       "3      184.0    193.0    190.0    189.5    172.0    132.0  ...     77.0   \n",
       "4      117.0    115.0    115.0    107.0     96.0     94.0  ...     59.0   \n",
       "..       ...      ...      ...      ...      ...      ...  ...      ...   \n",
       "655      NaN      NaN      NaN      NaN      NaN      NaN  ...    100.0   \n",
       "656      NaN      NaN      NaN      NaN      NaN      NaN  ...     93.0   \n",
       "657      NaN      NaN      NaN      NaN      NaN      NaN  ...    113.0   \n",
       "658      NaN      NaN      NaN      NaN      NaN      NaN  ...     49.0   \n",
       "659      NaN      NaN      NaN      NaN      NaN      NaN  ...    115.0   \n",
       "\n",
       "     2019-05  2019-06  2019-07  2019-08  2019-09  2019-10  2019-11  2019-12  \\\n",
       "0       67.0     67.0     69.0     71.0     75.0     77.0     77.0     83.0   \n",
       "1      119.0    115.0    117.0    121.0    129.0    133.0    138.0    137.0   \n",
       "2       62.0     63.0     65.0     67.0     68.0     70.0     69.0     74.0   \n",
       "3       72.0     74.0     77.0     81.0     85.0     92.0     95.0    101.0   \n",
       "4       57.0     57.0     59.0     61.0     70.0     74.0     74.0     80.0   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "655     83.0     59.0     64.0     69.0     94.0     99.0    133.0    121.5   \n",
       "656     78.0     71.0     73.0     77.0     88.0    113.0    114.0     97.0   \n",
       "657     93.0     93.0     91.0    132.5    107.0    116.0    140.0    161.0   \n",
       "658     40.0     44.0     44.0     42.5     46.5     49.0     46.0     47.0   \n",
       "659     75.0     62.0     68.0     59.0     64.5     61.0     73.0     76.5   \n",
       "\n",
       "     2020-01  \n",
       "0       93.0  \n",
       "1      143.0  \n",
       "2       81.0  \n",
       "3      116.0  \n",
       "4       84.0  \n",
       "..       ...  \n",
       "655    114.5  \n",
       "656    140.0  \n",
       "657    135.0  \n",
       "658     52.0  \n",
       "659    112.0  \n",
       "\n",
       "[660 rows x 125 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dependencies and Setup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "from scipy.stats import linregress\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "import scipy.stats as sts\n",
    "# Study data files_\n",
    "zillowdayspath = \"data_files/DaysonZillow.csv\"\n",
    "zillowpricepath = \"data_files/SalePrice.csv\"\n",
    "\n",
    "# Read the mouse data and the study results\n",
    "zillow_days_df = pd.read_csv(zillowdayspath)\n",
    "zillow_price_df = pd.read_csv(zillowpricepath)\n",
    "zillow_days_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>2019-01</th>\n",
       "      <th>2019-02</th>\n",
       "      <th>2019-03</th>\n",
       "      <th>2019-04</th>\n",
       "      <th>2019-05</th>\n",
       "      <th>2019-06</th>\n",
       "      <th>2019-07</th>\n",
       "      <th>2019-08</th>\n",
       "      <th>2019-09</th>\n",
       "      <th>2019-10</th>\n",
       "      <th>2019-11</th>\n",
       "      <th>2019-12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102001</td>\n",
       "      <td>United States</td>\n",
       "      <td>95.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>394913</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>140.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>753899</td>\n",
       "      <td>Los Angeles-Long Beach-Anaheim, CA</td>\n",
       "      <td>86.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>394463</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>114.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>394514</td>\n",
       "      <td>Dallas-Fort Worth, TX</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>394578</td>\n",
       "      <td>Evanston, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>121.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>395004</td>\n",
       "      <td>Prineville, OR</td>\n",
       "      <td>115.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>786263</td>\n",
       "      <td>Ruidoso, NM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.5</td>\n",
       "      <td>113.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>132.5</td>\n",
       "      <td>107.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>394805</td>\n",
       "      <td>Los Alamos, NM</td>\n",
       "      <td>54.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>46.5</td>\n",
       "      <td>49.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>395111</td>\n",
       "      <td>Spencer, IA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>64.5</td>\n",
       "      <td>61.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>76.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>660 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     RegionID                          RegionName  2019-01  2019-02  2019-03  \\\n",
       "0      102001                       United States     95.0     98.0     84.0   \n",
       "1      394913                        New York, NY    140.0    147.0    148.0   \n",
       "2      753899  Los Angeles-Long Beach-Anaheim, CA     86.0     89.0     70.0   \n",
       "3      394463                         Chicago, IL    114.0    122.0    117.0   \n",
       "4      394514               Dallas-Fort Worth, TX     77.0     77.0     63.0   \n",
       "..        ...                                 ...      ...      ...      ...   \n",
       "655    394578                        Evanston, WY      NaN      NaN    158.0   \n",
       "656    395004                      Prineville, OR    115.0    141.0    143.0   \n",
       "657    786263                         Ruidoso, NM      NaN      NaN     87.5   \n",
       "658    394805                      Los Alamos, NM     54.0     68.0     45.0   \n",
       "659    395111                         Spencer, IA      NaN      NaN      NaN   \n",
       "\n",
       "     2019-04  2019-05  2019-06  2019-07  2019-08  2019-09  2019-10  2019-11  \\\n",
       "0       72.0     67.0     67.0     69.0     71.0     75.0     77.0     77.0   \n",
       "1      139.0    119.0    115.0    117.0    121.0    129.0    133.0    138.0   \n",
       "2       64.0     62.0     63.0     65.0     67.0     68.0     70.0     69.0   \n",
       "3       77.0     72.0     74.0     77.0     81.0     85.0     92.0     95.0   \n",
       "4       59.0     57.0     57.0     59.0     61.0     70.0     74.0     74.0   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "655    100.0     83.0     59.0     64.0     69.0     94.0     99.0    133.0   \n",
       "656     93.0     78.0     71.0     73.0     77.0     88.0    113.0    114.0   \n",
       "657    113.0     93.0     93.0     91.0    132.5    107.0    116.0    140.0   \n",
       "658     49.0     40.0     44.0     44.0     42.5     46.5     49.0     46.0   \n",
       "659    115.0     75.0     62.0     68.0     59.0     64.5     61.0     73.0   \n",
       "\n",
       "     2019-12  \n",
       "0       83.0  \n",
       "1      137.0  \n",
       "2       74.0  \n",
       "3      101.0  \n",
       "4       80.0  \n",
       "..       ...  \n",
       "655    121.5  \n",
       "656     97.0  \n",
       "657    161.0  \n",
       "658     47.0  \n",
       "659     76.5  \n",
       "\n",
       "[660 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean up for 2019 only\n",
    "unwanted = zillow_days_df.columns[zillow_days_df.columns.str.startswith('2010')]\n",
    "zillow_days_df.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "unwanted = zillow_days_df.columns[zillow_days_df.columns.str.startswith('2011')]\n",
    "zillow_days_df.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "unwanted = zillow_days_df.columns[zillow_days_df.columns.str.startswith('2012')]\n",
    "zillow_days_df.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "unwanted = zillow_days_df.columns[zillow_days_df.columns.str.startswith('2013')]\n",
    "zillow_days_df.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "unwanted = zillow_days_df.columns[zillow_days_df.columns.str.startswith('2014')]\n",
    "zillow_days_df.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "unwanted = zillow_days_df.columns[zillow_days_df.columns.str.startswith('2015')]\n",
    "zillow_days_df.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "unwanted = zillow_days_df.columns[zillow_days_df.columns.str.startswith('2016')]\n",
    "zillow_days_df.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "unwanted = zillow_days_df.columns[zillow_days_df.columns.str.startswith('2017')]\n",
    "zillow_days_df.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "unwanted = zillow_days_df.columns[zillow_days_df.columns.str.startswith('2018')]\n",
    "zillow_days_df.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "unwanted = zillow_days_df.columns[zillow_days_df.columns.str.startswith('2020')]\n",
    "zillow_days_df.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "unwanted = zillow_days_df.columns[zillow_days_df.columns.str.startswith('Size')]\n",
    "zillow_days_df.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "unwanted = zillow_days_df.columns[zillow_days_df.columns.str.startswith('RegionType')]\n",
    "zillow_days_df.drop(unwanted, axis=1, inplace=True)\n",
    "zillow_days_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>2019-01</th>\n",
       "      <th>2019-02</th>\n",
       "      <th>2019-03</th>\n",
       "      <th>2019-04</th>\n",
       "      <th>2019-05</th>\n",
       "      <th>2019-06</th>\n",
       "      <th>2019-07</th>\n",
       "      <th>2019-08</th>\n",
       "      <th>2019-09</th>\n",
       "      <th>2019-10</th>\n",
       "      <th>2019-11</th>\n",
       "      <th>2019-12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102001</td>\n",
       "      <td>United States</td>\n",
       "      <td>226000</td>\n",
       "      <td>228300</td>\n",
       "      <td>230900</td>\n",
       "      <td>231500.0</td>\n",
       "      <td>231300.0</td>\n",
       "      <td>231900.0</td>\n",
       "      <td>232400.0</td>\n",
       "      <td>233100.0</td>\n",
       "      <td>233800.0</td>\n",
       "      <td>235900.0</td>\n",
       "      <td>239200.0</td>\n",
       "      <td>242100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>394913</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>386900</td>\n",
       "      <td>389400</td>\n",
       "      <td>390100</td>\n",
       "      <td>392500.0</td>\n",
       "      <td>392400.0</td>\n",
       "      <td>393700.0</td>\n",
       "      <td>394800.0</td>\n",
       "      <td>396100.0</td>\n",
       "      <td>398800.0</td>\n",
       "      <td>402900.0</td>\n",
       "      <td>408500.0</td>\n",
       "      <td>414100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>753899</td>\n",
       "      <td>Los Angeles-Long Beach-Anaheim, CA</td>\n",
       "      <td>626800</td>\n",
       "      <td>625900</td>\n",
       "      <td>631800</td>\n",
       "      <td>635600.0</td>\n",
       "      <td>633200.0</td>\n",
       "      <td>631200.0</td>\n",
       "      <td>633500.0</td>\n",
       "      <td>637900.0</td>\n",
       "      <td>642100.0</td>\n",
       "      <td>644400.0</td>\n",
       "      <td>650700.0</td>\n",
       "      <td>658300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>394463</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>219100</td>\n",
       "      <td>223600</td>\n",
       "      <td>233300</td>\n",
       "      <td>236200.0</td>\n",
       "      <td>232500.0</td>\n",
       "      <td>226500.0</td>\n",
       "      <td>222800.0</td>\n",
       "      <td>223300.0</td>\n",
       "      <td>224800.0</td>\n",
       "      <td>228000.0</td>\n",
       "      <td>229900.0</td>\n",
       "      <td>233900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>394514</td>\n",
       "      <td>Dallas-Fort Worth, TX</td>\n",
       "      <td>248500</td>\n",
       "      <td>249400</td>\n",
       "      <td>249400</td>\n",
       "      <td>250400.0</td>\n",
       "      <td>251200.0</td>\n",
       "      <td>252700.0</td>\n",
       "      <td>254000.0</td>\n",
       "      <td>256000.0</td>\n",
       "      <td>258400.0</td>\n",
       "      <td>261300.0</td>\n",
       "      <td>263500.0</td>\n",
       "      <td>265400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>395135</td>\n",
       "      <td>Storm Lake, IA</td>\n",
       "      <td>117900</td>\n",
       "      <td>130100</td>\n",
       "      <td>108300</td>\n",
       "      <td>111000.0</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>124000.0</td>\n",
       "      <td>125800.0</td>\n",
       "      <td>119600.0</td>\n",
       "      <td>128400.0</td>\n",
       "      <td>134900.0</td>\n",
       "      <td>140800.0</td>\n",
       "      <td>130100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>395236</td>\n",
       "      <td>Woodward, OK</td>\n",
       "      <td>111100</td>\n",
       "      <td>102200</td>\n",
       "      <td>108900</td>\n",
       "      <td>124700.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>118600.0</td>\n",
       "      <td>113300.0</td>\n",
       "      <td>122900.0</td>\n",
       "      <td>121000.0</td>\n",
       "      <td>135900.0</td>\n",
       "      <td>128500.0</td>\n",
       "      <td>132700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>394805</td>\n",
       "      <td>Los Alamos, NM</td>\n",
       "      <td>341800</td>\n",
       "      <td>357000</td>\n",
       "      <td>370200</td>\n",
       "      <td>352300.0</td>\n",
       "      <td>331800.0</td>\n",
       "      <td>336800.0</td>\n",
       "      <td>353700.0</td>\n",
       "      <td>378400.0</td>\n",
       "      <td>372700.0</td>\n",
       "      <td>380500.0</td>\n",
       "      <td>355800.0</td>\n",
       "      <td>340100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>395111</td>\n",
       "      <td>Spencer, IA</td>\n",
       "      <td>115500</td>\n",
       "      <td>117500</td>\n",
       "      <td>115200</td>\n",
       "      <td>125700.0</td>\n",
       "      <td>126800.0</td>\n",
       "      <td>131900.0</td>\n",
       "      <td>118500.0</td>\n",
       "      <td>129800.0</td>\n",
       "      <td>126800.0</td>\n",
       "      <td>129400.0</td>\n",
       "      <td>128400.0</td>\n",
       "      <td>134500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>395112</td>\n",
       "      <td>Spirit Lake, IA</td>\n",
       "      <td>237700</td>\n",
       "      <td>227800</td>\n",
       "      <td>221900</td>\n",
       "      <td>192600.0</td>\n",
       "      <td>217900.0</td>\n",
       "      <td>229700.0</td>\n",
       "      <td>223300.0</td>\n",
       "      <td>219200.0</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>203200.0</td>\n",
       "      <td>208000.0</td>\n",
       "      <td>207700.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>623 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     RegionID                          RegionName  2019-01  2019-02  2019-03  \\\n",
       "0      102001                       United States   226000   228300   230900   \n",
       "1      394913                        New York, NY   386900   389400   390100   \n",
       "2      753899  Los Angeles-Long Beach-Anaheim, CA   626800   625900   631800   \n",
       "3      394463                         Chicago, IL   219100   223600   233300   \n",
       "4      394514               Dallas-Fort Worth, TX   248500   249400   249400   \n",
       "..        ...                                 ...      ...      ...      ...   \n",
       "618    395135                      Storm Lake, IA   117900   130100   108300   \n",
       "619    395236                        Woodward, OK   111100   102200   108900   \n",
       "620    394805                      Los Alamos, NM   341800   357000   370200   \n",
       "621    395111                         Spencer, IA   115500   117500   115200   \n",
       "622    395112                     Spirit Lake, IA   237700   227800   221900   \n",
       "\n",
       "      2019-04   2019-05   2019-06   2019-07   2019-08   2019-09   2019-10  \\\n",
       "0    231500.0  231300.0  231900.0  232400.0  233100.0  233800.0  235900.0   \n",
       "1    392500.0  392400.0  393700.0  394800.0  396100.0  398800.0  402900.0   \n",
       "2    635600.0  633200.0  631200.0  633500.0  637900.0  642100.0  644400.0   \n",
       "3    236200.0  232500.0  226500.0  222800.0  223300.0  224800.0  228000.0   \n",
       "4    250400.0  251200.0  252700.0  254000.0  256000.0  258400.0  261300.0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "618  111000.0  107000.0  124000.0  125800.0  119600.0  128400.0  134900.0   \n",
       "619  124700.0  130000.0  118600.0  113300.0  122900.0  121000.0  135900.0   \n",
       "620  352300.0  331800.0  336800.0  353700.0  378400.0  372700.0  380500.0   \n",
       "621  125700.0  126800.0  131900.0  118500.0  129800.0  126800.0  129400.0   \n",
       "622  192600.0  217900.0  229700.0  223300.0  219200.0  221900.0  203200.0   \n",
       "\n",
       "      2019-11   2019-12  \n",
       "0    239200.0  242100.0  \n",
       "1    408500.0  414100.0  \n",
       "2    650700.0  658300.0  \n",
       "3    229900.0  233900.0  \n",
       "4    263500.0  265400.0  \n",
       "..        ...       ...  \n",
       "618  140800.0  130100.0  \n",
       "619  128500.0  132700.0  \n",
       "620  355800.0  340100.0  \n",
       "621  128400.0  134500.0  \n",
       "622  208000.0  207700.0  \n",
       "\n",
       "[623 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean up price for 2019 only\n",
    "\n",
    "unwanted = zillow_price_df.columns[zillow_price_df.columns.str.startswith('2008')]\n",
    "zillow_price_df.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "unwanted = zillow_price_df.columns[zillow_price_df.columns.str.startswith('2009')]\n",
    "zillow_price_df.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "unwanted = zillow_price_df.columns[zillow_price_df.columns.str.startswith('2010')]\n",
    "zillow_price_df.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "unwanted = zillow_price_df.columns[zillow_price_df.columns.str.startswith('2011')]\n",
    "zillow_price_df.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "unwanted = zillow_price_df.columns[zillow_price_df.columns.str.startswith('2012')]\n",
    "zillow_price_df.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "unwanted = zillow_price_df.columns[zillow_price_df.columns.str.startswith('2013')]\n",
    "zillow_price_df.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "unwanted = zillow_price_df.columns[zillow_price_df.columns.str.startswith('2014')]\n",
    "zillow_price_df.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "unwanted = zillow_price_df.columns[zillow_price_df.columns.str.startswith('2015')]\n",
    "zillow_price_df.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "unwanted = zillow_price_df.columns[zillow_price_df.columns.str.startswith('2016')]\n",
    "zillow_price_df.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "unwanted = zillow_price_df.columns[zillow_price_df.columns.str.startswith('2017')]\n",
    "zillow_price_df.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "unwanted = zillow_price_df.columns[zillow_price_df.columns.str.startswith('2018')]\n",
    "zillow_price_df.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "unwanted = zillow_price_df.columns[zillow_price_df.columns.str.startswith('2020')]\n",
    "zillow_price_df.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "unwanted = zillow_price_df.columns[zillow_price_df.columns.str.startswith('Size')]\n",
    "zillow_price_df.drop(unwanted, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "zillow_price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>RegionName_x</th>\n",
       "      <th>2019-01_x</th>\n",
       "      <th>2019-02_x</th>\n",
       "      <th>2019-03_x</th>\n",
       "      <th>2019-04_x</th>\n",
       "      <th>2019-05_x</th>\n",
       "      <th>2019-06_x</th>\n",
       "      <th>2019-07_x</th>\n",
       "      <th>2019-08_x</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-03_y</th>\n",
       "      <th>2019-04_y</th>\n",
       "      <th>2019-05_y</th>\n",
       "      <th>2019-06_y</th>\n",
       "      <th>2019-07_y</th>\n",
       "      <th>2019-08_y</th>\n",
       "      <th>2019-09_y</th>\n",
       "      <th>2019-10_y</th>\n",
       "      <th>2019-11_y</th>\n",
       "      <th>2019-12_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102001</td>\n",
       "      <td>United States</td>\n",
       "      <td>226000</td>\n",
       "      <td>228300</td>\n",
       "      <td>230900</td>\n",
       "      <td>231500.0</td>\n",
       "      <td>231300.0</td>\n",
       "      <td>231900.0</td>\n",
       "      <td>232400.0</td>\n",
       "      <td>233100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>394913</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>386900</td>\n",
       "      <td>389400</td>\n",
       "      <td>390100</td>\n",
       "      <td>392500.0</td>\n",
       "      <td>392400.0</td>\n",
       "      <td>393700.0</td>\n",
       "      <td>394800.0</td>\n",
       "      <td>396100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>148.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>753899</td>\n",
       "      <td>Los Angeles-Long Beach-Anaheim, CA</td>\n",
       "      <td>626800</td>\n",
       "      <td>625900</td>\n",
       "      <td>631800</td>\n",
       "      <td>635600.0</td>\n",
       "      <td>633200.0</td>\n",
       "      <td>631200.0</td>\n",
       "      <td>633500.0</td>\n",
       "      <td>637900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>394463</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>219100</td>\n",
       "      <td>223600</td>\n",
       "      <td>233300</td>\n",
       "      <td>236200.0</td>\n",
       "      <td>232500.0</td>\n",
       "      <td>226500.0</td>\n",
       "      <td>222800.0</td>\n",
       "      <td>223300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>117.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>394514</td>\n",
       "      <td>Dallas-Fort Worth, TX</td>\n",
       "      <td>248500</td>\n",
       "      <td>249400</td>\n",
       "      <td>249400</td>\n",
       "      <td>250400.0</td>\n",
       "      <td>251200.0</td>\n",
       "      <td>252700.0</td>\n",
       "      <td>254000.0</td>\n",
       "      <td>256000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>395130</td>\n",
       "      <td>Sterling, CO</td>\n",
       "      <td>147100</td>\n",
       "      <td>153000</td>\n",
       "      <td>155300</td>\n",
       "      <td>166000.0</td>\n",
       "      <td>164800.0</td>\n",
       "      <td>171400.0</td>\n",
       "      <td>162000.0</td>\n",
       "      <td>157800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>83.5</td>\n",
       "      <td>69.5</td>\n",
       "      <td>79.0</td>\n",
       "      <td>88.5</td>\n",
       "      <td>94.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>394418</td>\n",
       "      <td>Brookings, OR</td>\n",
       "      <td>315400</td>\n",
       "      <td>329700</td>\n",
       "      <td>331100</td>\n",
       "      <td>328600.0</td>\n",
       "      <td>336700.0</td>\n",
       "      <td>337800.0</td>\n",
       "      <td>338600.0</td>\n",
       "      <td>322700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>153.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>100.5</td>\n",
       "      <td>98.5</td>\n",
       "      <td>108.0</td>\n",
       "      <td>153.5</td>\n",
       "      <td>130.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>395004</td>\n",
       "      <td>Prineville, OR</td>\n",
       "      <td>252100</td>\n",
       "      <td>255900</td>\n",
       "      <td>256700</td>\n",
       "      <td>254700.0</td>\n",
       "      <td>277400.0</td>\n",
       "      <td>290300.0</td>\n",
       "      <td>284700.0</td>\n",
       "      <td>272600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>143.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>394805</td>\n",
       "      <td>Los Alamos, NM</td>\n",
       "      <td>341800</td>\n",
       "      <td>357000</td>\n",
       "      <td>370200</td>\n",
       "      <td>352300.0</td>\n",
       "      <td>331800.0</td>\n",
       "      <td>336800.0</td>\n",
       "      <td>353700.0</td>\n",
       "      <td>378400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>46.5</td>\n",
       "      <td>49.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>395111</td>\n",
       "      <td>Spencer, IA</td>\n",
       "      <td>115500</td>\n",
       "      <td>117500</td>\n",
       "      <td>115200</td>\n",
       "      <td>125700.0</td>\n",
       "      <td>126800.0</td>\n",
       "      <td>131900.0</td>\n",
       "      <td>118500.0</td>\n",
       "      <td>129800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>64.5</td>\n",
       "      <td>61.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>76.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>529 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     RegionID                        RegionName_x  2019-01_x  2019-02_x  \\\n",
       "0      102001                       United States     226000     228300   \n",
       "1      394913                        New York, NY     386900     389400   \n",
       "2      753899  Los Angeles-Long Beach-Anaheim, CA     626800     625900   \n",
       "3      394463                         Chicago, IL     219100     223600   \n",
       "4      394514               Dallas-Fort Worth, TX     248500     249400   \n",
       "..        ...                                 ...        ...        ...   \n",
       "524    395130                        Sterling, CO     147100     153000   \n",
       "525    394418                       Brookings, OR     315400     329700   \n",
       "526    395004                      Prineville, OR     252100     255900   \n",
       "527    394805                      Los Alamos, NM     341800     357000   \n",
       "528    395111                         Spencer, IA     115500     117500   \n",
       "\n",
       "     2019-03_x  2019-04_x  2019-05_x  2019-06_x  2019-07_x  2019-08_x  ...  \\\n",
       "0       230900   231500.0   231300.0   231900.0   232400.0   233100.0  ...   \n",
       "1       390100   392500.0   392400.0   393700.0   394800.0   396100.0  ...   \n",
       "2       631800   635600.0   633200.0   631200.0   633500.0   637900.0  ...   \n",
       "3       233300   236200.0   232500.0   226500.0   222800.0   223300.0  ...   \n",
       "4       249400   250400.0   251200.0   252700.0   254000.0   256000.0  ...   \n",
       "..         ...        ...        ...        ...        ...        ...  ...   \n",
       "524     155300   166000.0   164800.0   171400.0   162000.0   157800.0  ...   \n",
       "525     331100   328600.0   336700.0   337800.0   338600.0   322700.0  ...   \n",
       "526     256700   254700.0   277400.0   290300.0   284700.0   272600.0  ...   \n",
       "527     370200   352300.0   331800.0   336800.0   353700.0   378400.0  ...   \n",
       "528     115200   125700.0   126800.0   131900.0   118500.0   129800.0  ...   \n",
       "\n",
       "     2019-03_y  2019-04_y  2019-05_y  2019-06_y 2019-07_y  2019-08_y  \\\n",
       "0         84.0       72.0       67.0       67.0      69.0       71.0   \n",
       "1        148.0      139.0      119.0      115.0     117.0      121.0   \n",
       "2         70.0       64.0       62.0       63.0      65.0       67.0   \n",
       "3        117.0       77.0       72.0       74.0      77.0       81.0   \n",
       "4         63.0       59.0       57.0       57.0      59.0       61.0   \n",
       "..         ...        ...        ...        ...       ...        ...   \n",
       "524        NaN       71.0       63.0       83.5      69.5       79.0   \n",
       "525      153.0       86.0      117.0      100.5      98.5      108.0   \n",
       "526      143.0       93.0       78.0       71.0      73.0       77.0   \n",
       "527       45.0       49.0       40.0       44.0      44.0       42.5   \n",
       "528        NaN      115.0       75.0       62.0      68.0       59.0   \n",
       "\n",
       "     2019-09_y  2019-10_y  2019-11_y  2019-12_y  \n",
       "0         75.0       77.0       77.0       83.0  \n",
       "1        129.0      133.0      138.0      137.0  \n",
       "2         68.0       70.0       69.0       74.0  \n",
       "3         85.0       92.0       95.0      101.0  \n",
       "4         70.0       74.0       74.0       80.0  \n",
       "..         ...        ...        ...        ...  \n",
       "524       88.5       94.0       69.0       74.0  \n",
       "525      153.5      130.0      121.0      143.0  \n",
       "526       88.0      113.0      114.0       97.0  \n",
       "527       46.5       49.0       46.0       47.0  \n",
       "528       64.5       61.0       73.0       76.5  \n",
       "\n",
       "[529 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df =  pd.merge(zillow_price_df,zillow_days_df,on=\"RegionID\")\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>2019-01</th>\n",
       "      <th>2019-02</th>\n",
       "      <th>2019-03</th>\n",
       "      <th>2019-04</th>\n",
       "      <th>2019-05</th>\n",
       "      <th>2019-06</th>\n",
       "      <th>2019-07</th>\n",
       "      <th>2019-08</th>\n",
       "      <th>2019-09</th>\n",
       "      <th>2019-10</th>\n",
       "      <th>2019-11</th>\n",
       "      <th>2019-12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>660.000000</td>\n",
       "      <td>533.000000</td>\n",
       "      <td>562.000000</td>\n",
       "      <td>579.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>631.000000</td>\n",
       "      <td>644.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>660.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>413518.604545</td>\n",
       "      <td>102.351782</td>\n",
       "      <td>106.379004</td>\n",
       "      <td>99.415371</td>\n",
       "      <td>87.918919</td>\n",
       "      <td>77.766010</td>\n",
       "      <td>74.000792</td>\n",
       "      <td>74.305124</td>\n",
       "      <td>76.300758</td>\n",
       "      <td>80.013636</td>\n",
       "      <td>83.382576</td>\n",
       "      <td>86.079545</td>\n",
       "      <td>91.452273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>82088.292232</td>\n",
       "      <td>23.454194</td>\n",
       "      <td>25.818759</td>\n",
       "      <td>31.320460</td>\n",
       "      <td>31.201697</td>\n",
       "      <td>24.101209</td>\n",
       "      <td>21.024749</td>\n",
       "      <td>19.983266</td>\n",
       "      <td>18.400083</td>\n",
       "      <td>19.920513</td>\n",
       "      <td>20.675638</td>\n",
       "      <td>22.598699</td>\n",
       "      <td>22.242311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102001.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>394546.750000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>76.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>394797.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>75.500000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>86.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>395046.250000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>119.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>93.125000</td>\n",
       "      <td>97.500000</td>\n",
       "      <td>101.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>786263.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>213.500000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>196.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            RegionID     2019-01     2019-02     2019-03     2019-04  \\\n",
       "count     660.000000  533.000000  562.000000  579.000000  592.000000   \n",
       "mean   413518.604545  102.351782  106.379004   99.415371   87.918919   \n",
       "std     82088.292232   23.454194   25.818759   31.320460   31.201697   \n",
       "min    102001.000000   42.000000   47.000000   42.000000   42.000000   \n",
       "25%    394546.750000   86.000000   89.000000   75.000000   67.000000   \n",
       "50%    394797.000000   97.000000  103.000000   94.000000   80.000000   \n",
       "75%    395046.250000  116.000000  121.000000  119.500000   98.000000   \n",
       "max    786263.000000  196.000000  218.000000  213.500000  281.000000   \n",
       "\n",
       "          2019-05     2019-06     2019-07     2019-08     2019-09     2019-10  \\\n",
       "count  609.000000  631.000000  644.000000  660.000000  660.000000  660.000000   \n",
       "mean    77.766010   74.000792   74.305124   76.300758   80.013636   83.382576   \n",
       "std     24.101209   21.024749   19.983266   18.400083   19.920513   20.675638   \n",
       "min     40.000000   43.000000   44.000000   42.500000   46.000000   48.000000   \n",
       "25%     62.000000   61.000000   61.000000   63.500000   66.500000   69.000000   \n",
       "50%     71.000000   69.500000   70.000000   72.500000   75.500000   79.000000   \n",
       "75%     89.000000   82.000000   82.000000   85.000000   90.000000   93.125000   \n",
       "max    237.000000  252.000000  188.000000  164.000000  195.000000  194.000000   \n",
       "\n",
       "          2019-11     2019-12  \n",
       "count  660.000000  660.000000  \n",
       "mean    86.079545   91.452273  \n",
       "std     22.598699   22.242311  \n",
       "min     46.000000   47.000000  \n",
       "25%     70.000000   76.875000  \n",
       "50%     81.000000   86.750000  \n",
       "75%     97.500000  101.000000  \n",
       "max    217.000000  196.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zillow_days_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaned_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f64ab4a83ce2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Generate a summary statistics table of mean, median, variance, standard deviation, and SEM of the tumor volume for each regimen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# This method is the most straighforward, creating multiple series and putting them all together at the end.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cleaned_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate a summary statistics table of mean, median, variance, standard deviation, and SEM of the tumor volume for each regimen\n",
    "round(cleaned_df.describe(),2)\n",
    "# This method is the most straighforward, creating multiple series and putting them all together at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a bar plot showing the number of mice per time point for each treatment throughout the course of the study using pandas.\n",
    "mice_per_treament_df = cleaned_df\n",
    "counts_df = mice_per_treament_df.groupby('Timepoint').nunique()\n",
    "mice_df = counts_df\n",
    "labels= ['0','5','10','15','20','30','35','40','45']\n",
    "ax = mice_df.plot.bar(y='Mouse ID', rot=0)\n",
    "plt.ylabel(\"Count of Mice\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a bar plot showing the number of mice per time point for each treatment throughout the course of the study using pyplot.\n",
    "\n",
    "\n",
    "x_axis = np.arange(len(mice_df))\n",
    "tick_locations = [value for value in x_axis]\n",
    "labels= ['0','5','10','15','20','25','30','35','40','45']\n",
    "values = mice_df[\"Mouse ID\"]\n",
    "tick_locations = [values+0.4 for value in x_axis]\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.bar(labels, values)\n",
    "plt.title('Count of mice v time point ')\n",
    "plt.ylabel('Count of mice')\n",
    "plt.subplot(132)\n",
    "plt.scatter(labels, values)\n",
    "plt.subplot(133)\n",
    "plt.plot(labels, values)\n",
    "plt.title('Count of mice v time point ')\n",
    "plt.ylabel('Count of mice')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "mice_df.plot.barh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pie Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a pie plot showing the distribution of female versus male mice using pandas\n",
    "mice_gender_df = drop_dup_df.groupby(\"Sex\")\n",
    "male = mouse_metadata[\"Sex\"].value_counts()['Male']\n",
    "female = mouse_metadata[\"Sex\"].value_counts()['Female']\n",
    "mice=male+female\n",
    "df= pd.DataFrame({'sex': [male, female]},index=['male', 'female'])\n",
    "df.plot.pie(y='sex', figsize=(4, 4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a pie plot showing the distribution of female versus male mice using pyplot\n",
    "mice_gender_df = drop_dup_df.groupby(\"Sex\")\n",
    "male = mouse_metadata[\"Sex\"].value_counts()['Male']\n",
    "female = mouse_metadata[\"Sex\"].value_counts()['Female']\n",
    "mice=male+female\n",
    "mice_gender_df.head()\n",
    "\n",
    "print('male:', male, 'Female: ', female, 'Total: ', mice)\n",
    "#pyplot pie\n",
    "# Labels for the sections of our pie chart\n",
    "labels = [\"Male\", \"Female\"]\n",
    "\n",
    "# The values of each section of the pie chart\n",
    "sizes = [male, female]\n",
    "\n",
    "# The colors of each section of the pie chart\n",
    "colors = [\"cyan\", \"pink\"]\n",
    "\n",
    "# Tells matplotlib to seperate the \"Humans\" section from the others\n",
    "explode = (0.1, 0,)\n",
    "           \n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "        autopct=\"%1.1f%%\", shadow=True, startangle=140)           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quartiles, Outliers and Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the final tumor volume of each mouse across four of the most promising treatment regimens. \n",
    " \n",
    "treatment_df = drop_dup_df[drop_dup_df['Timepoint']==45]\n",
    "\n",
    "treatment_df = treatment_df.sort_values(\"Drug Regimen\")\n",
    "treatment_df = treatment_df.reset_index(drop=True)\n",
    "\n",
    "treatment_df = treatment_df.rename({\"Drug Regimen\": \"Treatment\",\"Tumor Volume (mm3)\":\"Final_vol\"}, axis = 'columns')\n",
    "treatments = treatment_df[\"Treatment\"].unique()\n",
    "\n",
    "treatment_df\n",
    "treatment_vol = treatment_df[['Treatment','Final_vol']]\n",
    "\n",
    "treat_avg = treatment_vol.groupby('Treatment').mean()\n",
    "\n",
    "treat_avg = treat_avg.sort_values(\"Final_vol\")\n",
    "print('Top 4 treatments')\n",
    "print(treat_avg.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Outlier Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create individual data frames for each treatment(Drug Regimen)\n",
    "#Ramicane\n",
    "Ramicane_df = treatment_vol[treatment_vol['Treatment']=='Ramicane']\n",
    "Ramicane_df = Ramicane_df.reset_index(drop=True)\n",
    "Ramicane_df = Ramicane_df.rename({\"Treatment\": \"TRamicane\",\"Final_vol\":\"Ramicane\"}, axis = 'columns')\n",
    "#Capomulin\n",
    "Capomulin_df = treatment_vol[treatment_vol['Treatment']=='Capomulin']\n",
    "Capomulin_df = Capomulin_df.reset_index(drop=True)\n",
    "Capomulin_df = Capomulin_df.rename({\"Treatment\": \"TCopomulin\",\"Final_vol\":\"Capomulin\"}, axis = 'columns')\n",
    "#Ceftamin\n",
    "Ceftamin_df = treatment_vol[treatment_vol['Treatment']=='Ceftamin']\n",
    "Ceftamin_df = Ceftamin_df.reset_index(drop=True)\n",
    "Ceftamin_df = Ceftamin_df.rename({\"Treatment\": \"TCeftamin\",\"Final_vol\":\"Ceftamin\"}, axis = 'columns')\n",
    "#infbinol\n",
    "Infubinol_df = treatment_vol[treatment_vol['Treatment']=='Infubinol']\n",
    "Infubinol_df = Infubinol_df.reset_index(drop=True)\n",
    "Infubinol_df = Infubinol_df.rename({\"Treatment\": \"TInfubinol\",\"Final_vol\":\"Infubinol\"}, axis = 'columns')\n",
    "#Placebo (control group)\n",
    "Placebo_df = treatment_vol[treatment_vol['Treatment']=='Placebo']\n",
    "Placebo_df = Placebo_df.reset_index(drop=True)\n",
    "Placebo_df = Placebo_df.rename({\"Treatment\": \"TPlacebo\",\"Final_vol\":\"Placebo\"}, axis = 'columns')\n",
    "\n",
    "print(treatment_vol)\n",
    "a=Ramicane_df.iloc[:,1:].values  \n",
    "b=Capomulin_df.iloc[:,1:].values \n",
    "c=Ceftamin_df.iloc[:,1:].values \n",
    "d=Infubinol_df.iloc[:,1:].values\n",
    "\n",
    "print(Ramicane_df)\n",
    "print(Capomulin_df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_stack = pd.concat([Ramicane_df, Capomulin_df,Ceftamin_df,Infubinol_df,Placebo_df], axis=1)\n",
    "\n",
    "df=horizontal_stack\n",
    "\n",
    "\n",
    "df=df.drop(df.columns[[0,2,4,6,8]], axis = 1)\n",
    "\n",
    "\n",
    "Ramicane = df['Ramicane']\n",
    "Capomulin = df['Capomulin']\n",
    "Ceftamin = df['Ceftamin']\n",
    "Infubinol = df['Infubinol']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the IQR and quantitatively determine if there are any potential outliers.\n",
    "\n",
    "\n",
    "q_ram = Ramicane.quantile([.25,.5,.75])\n",
    "lowerq_ram = q_ram[0.25]\n",
    "upperq_ram = q_ram[0.75]\n",
    "iqr_ram = upperq_ram-lowerq_ram\n",
    "q_cap = Capomulin.quantile([.25,.5,.75])\n",
    "lowerq_cap = q_cap[0.25]\n",
    "upperq_cap = q_cap[0.75]\n",
    "iqr_cap = upperq_cap-lowerq_cap\n",
    "iqr_ram\n",
    "iqr_cap\n",
    "\n",
    "lbcap = lowerq_cap - (1.5*iqr_cap)\n",
    "ubcap = upperq_cap + (1.5*iqr_cap)\n",
    "cap_outliers = Capomulin_df.loc[(Capomulin_df['Capomulin'] < lowerq_cap) | (Capomulin_df['Capomulin'] > upperq_cap)]\n",
    "\n",
    "print(cap_outliers)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a function to create density plots for the df of treatment tumor volume\n",
    "# note this is a free-to-use function not the original code of this student\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "import warnings\n",
    "\n",
    "try:\n",
    "    from pandas.plotting._tools import (_subplots, _flatten)\n",
    "except:\n",
    "    #TODO this is a quick fix for #38\n",
    "    from pandas.plotting._matplotlib.tools import (_subplots, _flatten)\n",
    "\n",
    "from pandas import (DataFrame, Series)\n",
    "from pandas.core.dtypes.common import is_number\n",
    "from pandas.core.groupby import DataFrameGroupBy\n",
    "from matplotlib import pyplot as plt\n",
    "from warnings import warn\n",
    "\n",
    "_DEBUG = False\n",
    "\n",
    "def _x_range(data, extra=0.1):\n",
    "    \"\"\" Compute the x_range, i.e., the values for which the\n",
    "        density will be computed. It should be slightly larger than\n",
    "        the max and min so that the plot actually reaches 0, and\n",
    "        also has a bit of a tail on both sides.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sample_range = np.nanmax(data) - np.nanmin(data)\n",
    "    except ValueError:\n",
    "        return []\n",
    "    if sample_range < 1e-6:\n",
    "        return [np.nanmin(data), np.nanmax(data)]\n",
    "    return np.linspace(np.nanmin(data) - extra*sample_range,\n",
    "                       np.nanmax(data) + extra*sample_range, 1000)\n",
    "def _setup_axis(ax, x_range, col_name=None, grid=False, ylabelsize=None, yrot=None):   # jp axis\n",
    "    \"\"\" Setup the axis for the joyplot:\n",
    "        - add the y label if required (as an ytick)\n",
    "        - add y grid if required\n",
    "        - make the background transparent\n",
    "        - set the xlim according to the x_range\n",
    "        - hide the xaxis and the spines\n",
    "    \"\"\"\n",
    "    if col_name is not None:\n",
    "        ax.set_yticks([0])\n",
    "        ax.set_yticklabels([col_name], fontsize=ylabelsize, rotation=yrot)\n",
    "        ax.yaxis.grid(grid)\n",
    "    else:\n",
    "        ax.yaxis.set_visible(False)\n",
    "    ax.patch.set_alpha(0)\n",
    "    ax.set_xlim(20, 80)                                       #set x range here\n",
    "    #ax.set_xlim([min(x_range), max(x_range)])\n",
    "    ax.tick_params(axis='both', which='both', length=0, pad=10)\n",
    "    ax.xaxis.set_visible(_DEBUG)\n",
    "    ax.set_frame_on(_DEBUG)\n",
    "\n",
    "def _is_numeric(x):\n",
    "    \"\"\" Whether the array x is numeric. \"\"\"\n",
    "    return all(is_number(i) for i in x)\n",
    "\n",
    "def _get_alpha(i, n, start=0.4, end=1.0):\n",
    "    \"\"\" Compute alpha value at position i out of n \"\"\"\n",
    "    return start + (1 + i)*(end - start)/n\n",
    "\n",
    "def _remove_na(l):\n",
    "    \"\"\" Remove NA values. Should work for lists, arrays, series. \"\"\"\n",
    "    return Series(l).dropna().values\n",
    "\n",
    "def _moving_average(a, n=3, zero_padded=False):\n",
    "    \"\"\" Moving average of order n.\n",
    "        If zero padded, returns an array of the same size as\n",
    "        the input: the values before a[0] are considered to be 0.\n",
    "        Otherwise, returns an array of length len(a) - n + 1 \"\"\"\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    if zero_padded:\n",
    "        return ret / n\n",
    "    else:\n",
    "        return ret[n - 1:] / n\n",
    "\n",
    "def joyplot(data, column=None, by=None, grid=False,\n",
    "            xlabelsize=None, xrot=None, ylabelsize=None, yrot=None,\n",
    "            ax=None, figsize=None,\n",
    "            hist=False, bins=10,\n",
    "            fade=False, ylim='max',\n",
    "            fill=True, linecolor=None,                                  #chng 1 to 2\n",
    "            overlap=1, background=None,\n",
    "            labels=None, xlabels=True, ylabels=True,\n",
    "            range_style='all',\n",
    "            x_range=None,\n",
    "            title=None,\n",
    "            colormap=None,\n",
    "            color=None,\n",
    "            **kwds):\n",
    "    \"\"\"\n",
    "    Draw joyplot of a DataFrame, or appropriately nested collection,\n",
    "    using matplotlib and pandas.\n",
    "    A joyplot is a stack of vertically aligned density plots / histograms.\n",
    "    By default, if 'data' is a DataFrame,\n",
    "    this function will plot a density plot for each column.\n",
    "    This wrapper method tries to convert whatever structure is given\n",
    "    to a nested collection of lists with additional information\n",
    "    on labels, and use the private _joyplot function to actually\n",
    "    draw theh plot.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : DataFrame, Series or nested collection\n",
    "    column : string or sequence\n",
    "        If passed, will be used to limit data to a subset of columns\n",
    "    by : object, optional\n",
    "        If passed, used to form separate plot groups\n",
    "    grid : boolean, default True\n",
    "        Whether to show axis grid lines\n",
    "    labels : boolean or list, default True.\n",
    "        If list, must be the same size of the de\n",
    "    xlabelsize : int, default None\n",
    "        If specified changes the x-axis label size\n",
    "    xrot : float, default None\n",
    "        rotation of x axis labels\n",
    "    ylabelsize : int, default None\n",
    "        If specified changes the y-axis label size\n",
    "    yrot : float, default None\n",
    "        rotation of y axis labels\n",
    "    ax : matplotlib axes object, default None\n",
    "    figsize : tuple\n",
    "        The size of the figure to create in inches by default\n",
    "    hist : boolean, default False\n",
    "    bins : integer, default 10\n",
    "        Number of histogram bins to be used\n",
    "    color : color or colors to be used in the plots. It can be:\n",
    "        a string or anything interpretable as color by matplotib;\n",
    "        a list of colors. See docs / examples for more details.\n",
    "    kwds : other plotting keyword arguments\n",
    "        To be passed to hist/kde plot function\n",
    "    \"\"\"\n",
    "\n",
    "    if column is not None:\n",
    "        if not isinstance(column, (list, np.ndarray)):\n",
    "            column = [column]\n",
    "\n",
    "    def _grouped_df_to_standard(grouped, column):\n",
    "        converted = []\n",
    "        labels = []\n",
    "        for i, (key, group) in enumerate(grouped):\n",
    "            if column is not None:\n",
    "                group = group[column]\n",
    "            labels.append(key)\n",
    "            converted.append([_remove_na(group[c]) for c in group.columns if _is_numeric(group[c])])\n",
    "            if i == 0:\n",
    "                sublabels = [col for col in group.columns if _is_numeric(group[col])]\n",
    "        return converted, labels, sublabels\n",
    "\n",
    "    #################################################################\n",
    "    # GROUPED\n",
    "    # - given a grouped DataFrame, a group by key, or a dict of dicts of Series/lists/arrays\n",
    "    # - select the required columns/Series/lists/arrays\n",
    "    # - convert to standard format: list of lists of non-null arrays\n",
    "    #   + extra parameters (labels and sublabels)\n",
    "    #################################################################\n",
    "    if isinstance(data, DataFrameGroupBy):\n",
    "        grouped = data\n",
    "        converted, _labels, sublabels = _grouped_df_to_standard(grouped, column)\n",
    "        if labels is None:\n",
    "            labels = _labels\n",
    "    elif by is not None and isinstance(data, DataFrame):\n",
    "        grouped = data.groupby(by)\n",
    "        if column is None:\n",
    "            # Remove the groupby key. It's not automatically removed by pandas.\n",
    "            column = list(data.columns).remove(by)\n",
    "        converted, _labels, sublabels = _grouped_df_to_standard(grouped, column)\n",
    "        if labels is None:\n",
    "            labels = _labels\n",
    "        # If there is at least an element which is not a list of lists.. go on.\n",
    "    elif isinstance(data, dict) and all(isinstance(g, dict) for g in data.values()):\n",
    "        grouped = data\n",
    "        if labels is None:\n",
    "            labels = list(grouped.keys())\n",
    "        converted = []\n",
    "        for i, (key, group) in enumerate(grouped.items()):\n",
    "            if column is not None:\n",
    "                converted.append([_remove_na(g) for k,g in group.items() if _is_numeric(g) and k in column])\n",
    "                if i == 0:\n",
    "                    sublabels = [k for k,g in group.items() if _is_numeric(g)]\n",
    "            else:\n",
    "                converted.append([_remove_na(g) for k,g in group.items() if _is_numeric(g)])\n",
    "                if i == 0:\n",
    "                    sublabels = [k for k,g in group.items() if _is_numeric(g)]\n",
    "    #################################################################\n",
    "    # PLAIN:\n",
    "    # - given a DataFrame or list/dict of Series/lists/arrays\n",
    "    # - select the required columns/Series/lists/arrays\n",
    "    # - convert to standard format: list of lists of non-null arrays + extra parameter (labels)\n",
    "    #################################################################\n",
    "    elif isinstance(data, DataFrame):\n",
    "        if column is not None:\n",
    "            data = data[column]\n",
    "        converted = [[_remove_na(data[col])] for col in data.columns if _is_numeric(data[col])]\n",
    "        labels = [col for col in data.columns if _is_numeric(data[col])]\n",
    "        sublabels = None\n",
    "    elif isinstance(data, dict):\n",
    "        if column is not None:\n",
    "            converted = [[_remove_na(g)] for k,g in data.items() if _is_numeric(g) and k in column]\n",
    "            labels = [k for k,g in data.items() if _is_numeric(g) and k in column]\n",
    "        else:\n",
    "            converted = [[_remove_na(g)] for k,g in data.items() if _is_numeric(g)]\n",
    "            labels = [k for k,g in data.items() if _is_numeric(g)]\n",
    "        sublabels = None\n",
    "    elif isinstance(data, list):\n",
    "        if column is not None:\n",
    "            converted = [[_remove_na(g)] for g in data if _is_numeric(g) and i in column]\n",
    "        else:\n",
    "            converted = [[_remove_na(g)] for g in data if _is_numeric(g)]\n",
    "        if labels and len(labels) != len(converted):\n",
    "            raise ValueError(\"The number of labels does not match the length of the list.\")\n",
    "\n",
    "        sublabels = None\n",
    "    else:\n",
    "        raise TypeError(\"Unknown type for 'data': {!r}\".format(type(data)))\n",
    "\n",
    "    if ylabels is False:\n",
    "        labels = None\n",
    "\n",
    "    if all(len(subg)==0 for g in converted for subg in g):\n",
    "        raise ValueError(\"No numeric values found. Joyplot requires at least a numeric column/group.\")\n",
    "\n",
    "    if any(len(subg)==0 for g in converted for subg in g):\n",
    "        warn(\"At least a column/group has no numeric values.\")\n",
    "\n",
    "\n",
    "    return _joyplot(converted, labels=labels, sublabels=sublabels,\n",
    "                    grid=grid,\n",
    "                    xlabelsize=xlabelsize, xrot=xrot, ylabelsize=ylabelsize, yrot=yrot,\n",
    "                    ax=ax, figsize=figsize,\n",
    "                    hist=hist, bins=bins,\n",
    "                    fade=fade, ylim=ylim,\n",
    "                    fill=fill, linecolor=linecolor,\n",
    "                    overlap=overlap, background=background,\n",
    "                    xlabels=xlabels,\n",
    "                    range_style=range_style, x_range=x_range,\n",
    "                    title=title,\n",
    "                    colormap=colormap,\n",
    "                    color=color,\n",
    "                    **kwds)\n",
    "\n",
    "###########################################\n",
    "\n",
    "def plot_density(ax, x_range, v, kind=\"kde\", bw_method=None,\n",
    "                 bins=50,\n",
    "                 fill=False, linecolor=None, clip_on=True, **kwargs):\n",
    "    \"\"\" Draw a density plot given an axis, an array of values v and an array\n",
    "        of x positions where to return the estimated density.\n",
    "    \"\"\"\n",
    "    v = _remove_na(v)\n",
    "    if len(v) == 0 or len(x_range) == 0:\n",
    "        return\n",
    "\n",
    "    if kind == \"kde\":\n",
    "        try:\n",
    "            gkde = gaussian_kde(v, bw_method=bw_method)\n",
    "            y = gkde.evaluate(x_range)\n",
    "        except ValueError:\n",
    "            # Handle cases where there is no data in a group.\n",
    "            y = np.zeros_like(x_range)\n",
    "        except np.linalg.LinAlgError as e:\n",
    "            # Handle singular matrix in kde computation.\n",
    "            distinct_values = np.unique(v)\n",
    "            if len(distinct_values) == 1:\n",
    "                # In case of a group with a single value val,\n",
    "                # that should have infinite density,\n",
    "                # return a δ(val)\n",
    "                val = distinct_values[0]\n",
    "                warnings.warn(\"The data contains a group with a single distinct value ({}) \"\n",
    "                              \"having infinite probability density. \"\n",
    "                              \"Consider using a different visualization.\".format(val))\n",
    "\n",
    "                # Find index i of x_range\n",
    "                # such that x_range[i-1] < val ≤ x_range[i]\n",
    "                i = np.searchsorted(x_range, val)\n",
    "\n",
    "                y = np.zeros_like(x_range)\n",
    "                y[i] = 1\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "    elif kind == \"counts\":\n",
    "        y, bin_edges = np.histogram(v, bins=bins, range=(min(x_range), max(x_range)))\n",
    "        # np.histogram returns the edges of the bins.\n",
    "        # We compute here the middle of the bins.\n",
    "        x_range = _moving_average(bin_edges, 2)\n",
    "    elif kind == \"normalized_counts\":\n",
    "        y, bin_edges = np.histogram(v, bins=bins, density=False,\n",
    "                                    range=(min(x_range), max(x_range)))\n",
    "        # np.histogram returns the edges of the bins.\n",
    "        # We compute here the middle of the bins.\n",
    "        y = y / len(v)\n",
    "        x_range = _moving_average(bin_edges, 2)\n",
    "    elif kind == \"values\":\n",
    "        # Warning: to use values and get a meaningful visualization,\n",
    "        # x_range must also be manually set in the main function.\n",
    "        y = v\n",
    "        x_range = list(range(len(y)))\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    if fill:\n",
    "        ax.fill_between(x_range, 0.0, y, clip_on=clip_on, **kwargs)\n",
    "\n",
    "        # Hack to have a border at the bottom at the fill patch\n",
    "        # (of the same color of the fill patch)\n",
    "        # so that the fill reaches the same bottom margin as the edge lines\n",
    "        # with y value = 0.0\n",
    "        kw = kwargs\n",
    "        kw[\"label\"] = None\n",
    "        ax.plot(x_range, [0.0]*len(x_range), clip_on=clip_on, **kw)\n",
    "\n",
    "    if linecolor is not None:\n",
    "        kwargs[\"color\"] = linecolor\n",
    "\n",
    "    # Remove the legend labels if we are plotting filled curve:\n",
    "    # we only want one entry per group in the legend (if shown).\n",
    "    if fill:\n",
    "        kwargs[\"label\"] = None\n",
    "\n",
    "    ax.plot(x_range, y, clip_on=clip_on, **kwargs)\n",
    "\n",
    "###########################################\n",
    "\n",
    "def _joyplot(data,\n",
    "             grid=False,\n",
    "             labels=None, sublabels=None,\n",
    "             xlabels=True,\n",
    "             xlabelsize=None, xrot=None,\n",
    "             ylabelsize=None, yrot=None,\n",
    "             ax=None, figsize=None,\n",
    "             hist=False, bins=10,                       #hist = true\n",
    "             fade=False,\n",
    "             xlim=None, ylim='max',\n",
    "             fill=True, linecolor=None,\n",
    "             overlap=1, background=None,\n",
    "             range_style='all', x_range=None, tails=0.8,\n",
    "             title=None,\n",
    "             legend=False, loc=\"upper right\",\n",
    "             colormap=None, color=None,\n",
    "             **kwargs):\n",
    "    \"\"\"\n",
    "    Internal method.\n",
    "    Draw a joyplot from an appropriately nested collection of lists\n",
    "    using matplotlib and pandas.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : DataFrame, Series or nested collection\n",
    "    grid : boolean, default True\n",
    "        Whether to show axis grid lines\n",
    "    labels : boolean or list, default True.\n",
    "        If list, must be the same size of the de\n",
    "    xlabelsize : int, default None\n",
    "        If specified changes the x-axis label size\n",
    "    xrot : float, default None\n",
    "        rotation of x axis labels\n",
    "    ylabelsize : int, default None\n",
    "        If specified changes the y-axis label size\n",
    "    yrot : float, default None\n",
    "        rotation of y axis labels\n",
    "    ax : matplotlib axes object, default None\n",
    "    figsize : tuple\n",
    "        The size of the figure to create in inches by default\n",
    "    hist : boolean, default False\n",
    "    bins : integer, default 10\n",
    "        Number of histogram bins to be used\n",
    "    kwarg : other plotting keyword arguments\n",
    "        To be passed to hist/kde plot function\n",
    "    \"\"\"\n",
    "\n",
    "    if fill is True and linecolor is None:\n",
    "        linecolor = \"k\"\n",
    "\n",
    "    if sublabels is None:\n",
    "        legend = False\n",
    "\n",
    "    def _get_color(i, num_axes, j, num_subgroups):\n",
    "        if isinstance(color, list):\n",
    "            return color[j] if num_subgroups > 1 else color[i]\n",
    "        elif color is not None:\n",
    "            return color\n",
    "        elif isinstance(colormap, list):\n",
    "            return colormap[j](i/num_axes)\n",
    "        elif color is None and colormap is None:\n",
    "            num_cycle_colors = len(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "            return plt.rcParams['axes.prop_cycle'].by_key()['color'][j % num_cycle_colors]\n",
    "        else:\n",
    "            return colormap(i/num_axes)\n",
    "\n",
    "    ygrid = (grid is True or grid == 'y' or grid == 'both')\n",
    "    xgrid = (grid is True or grid == 'x' or grid == 'both')\n",
    "\n",
    "    num_axes = len(data)\n",
    "\n",
    "    if x_range is None:\n",
    "        global_x_range = _x_range([v for g in data for sg in g for v in sg])\n",
    "    else:\n",
    "        global_x_range = _x_range(x_range, 0.0)\n",
    "    global_x_min, global_x_max = min(global_x_range), max(global_x_range)\n",
    "\n",
    "    # Each plot will have its own axis\n",
    "    fig, axes = _subplots(naxes=num_axes, ax=ax, squeeze=False,\n",
    "                          sharex=True, sharey=False, figsize=figsize,\n",
    "                          layout_type='vertical')\n",
    "    _axes = _flatten(axes)\n",
    "\n",
    "    # The legend must be drawn in the last axis if we want it at the bottom.\n",
    "    if loc in (3, 4, 8) or 'lower' in str(loc):\n",
    "        legend_axis = num_axis - 1\n",
    "    else:\n",
    "        legend_axis = 0\n",
    "\n",
    "    # A couple of simple checks.\n",
    "    if labels is not None:\n",
    "        assert len(labels) == num_axes\n",
    "    if sublabels is not None:\n",
    "        assert all(len(g) == len(sublabels) for g in data)\n",
    "    if isinstance(color, list):\n",
    "        assert all(len(g) <= len(color) for g in data)\n",
    "    if isinstance(colormap, list):\n",
    "        assert all(len(g) == len(colormap) for g in data)\n",
    "\n",
    "    for i, group in enumerate(data):\n",
    "        a = _axes[i]\n",
    "        group_zorder = i\n",
    "        if fade:\n",
    "            kwargs['alpha'] = _get_alpha(i, num_axes)\n",
    "\n",
    "        num_subgroups = len(group)\n",
    "\n",
    "        if hist:\n",
    "            # matplotlib hist() already handles multiple subgroups in a histogram\n",
    "            a.hist(group, label=sublabels, bins=bins, color=color,\n",
    "                   range=[min(global_x_range), max(global_x_range)],\n",
    "                   edgecolor=linecolor, zorder=group_zorder, **kwargs)\n",
    "        else:\n",
    "            for j, subgroup in enumerate(group):\n",
    "\n",
    "                # Compute the x_range of the current plot\n",
    "                if range_style == 'all':\n",
    "                # All plots have the same range\n",
    "                    x_range = global_x_range\n",
    "                elif range_style == 'own':\n",
    "                # Each plot has its own range\n",
    "                    x_range = _x_range(subgroup, tails)\n",
    "                elif range_style == 'group':\n",
    "                # Each plot has a range that covers the whole group\n",
    "                    x_range = _x_range(group, tails)\n",
    "                elif isinstance(range_style, (list, np.ndarray)):\n",
    "                # All plots have exactly the range passed as argument\n",
    "                    x_range = _x_range(range_style, 0.0)\n",
    "                else:\n",
    "                    raise NotImplementedError(\"Unrecognized range style.\")\n",
    "\n",
    "                if sublabels is None:\n",
    "                    sublabel = None\n",
    "                else:\n",
    "                    sublabel = sublabels[j]\n",
    "\n",
    "                element_zorder = group_zorder + j/(num_subgroups+1)\n",
    "                element_color = _get_color(i, num_axes, j, num_subgroups)\n",
    "\n",
    "                plot_density(a, x_range, subgroup,\n",
    "                             fill=fill, linecolor=linecolor, label=sublabel,\n",
    "                             zorder=element_zorder, color=element_color,\n",
    "                             bins=bins, **kwargs)\n",
    "\n",
    "\n",
    "        # Setup the current axis: transparency, labels, spines.\n",
    "        col_name = None if labels is None else labels[i]\n",
    "        _setup_axis(a, global_x_range, col_name=col_name, grid=ygrid,\n",
    "                ylabelsize=ylabelsize, yrot=yrot)\n",
    "\n",
    "        # When needed, draw the legend\n",
    "        if legend and i == legend_axis:\n",
    "            a.legend(loc=loc)\n",
    "            # Bypass alpha values, in case\n",
    "            for p in a.get_legend().get_patches():\n",
    "                p.set_facecolor(p.get_facecolor())\n",
    "                p.set_alpha(1.0)\n",
    "            for l in a.get_legend().get_lines():\n",
    "                l.set_alpha(1.0)\n",
    "\n",
    "\n",
    "    # Final adjustments\n",
    "\n",
    "    # Set the y limit for the density plots.\n",
    "    # Since the y range in the subplots can vary significantly,\n",
    "    # different options are available.\n",
    "    if ylim == 'max':\n",
    "        # Set all yaxis limit to the same value (max range among all)\n",
    "        max_ylim = max(a.get_ylim()[1] for a in _axes)\n",
    "        min_ylim = min(a.get_ylim()[0] for a in _axes)\n",
    "        for a in _axes:\n",
    "            a.set_ylim([min_ylim - 0.1*(max_ylim-min_ylim), max_ylim])\n",
    "\n",
    "    elif ylim == 'own':\n",
    "        # Do nothing, each axis keeps its own ylim\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        # Set all yaxis lim to the argument value ylim\n",
    "        try:\n",
    "            for a in _axes:\n",
    "                a.set_ylim(ylim)\n",
    "        except:\n",
    "            print(\"Warning: the value of ylim must be either 'max', 'own', or a tuple of length 2. The value you provided has no effect.\")\n",
    "\n",
    "    # Compute a final axis, used to apply global settings\n",
    "    last_axis = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    # Background color\n",
    "    if background is not None:\n",
    "        last_axis.patch.set_facecolor(background)\n",
    "\n",
    "    for side in ['top', 'bottom', 'left', 'right']:\n",
    "        last_axis.spines[side].set_visible(_DEBUG)\n",
    "\n",
    "    # This looks hacky, but all the axes share the x-axis,\n",
    "    # so they have the same lims and ticks\n",
    "    last_axis.set_xlim(_axes[0].get_xlim())\n",
    "    if xlabels is True:\n",
    "        last_axis.set_xticks(np.array(_axes[0].get_xticks()[1:-1]))\n",
    "        for t in last_axis.get_xticklabels():\n",
    "            t.set_visible(True)\n",
    "            t.set_fontsize(xlabelsize)\n",
    "            t.set_rotation(xrot)\n",
    "\n",
    "        # If grid is enabled, do not allow xticks (they are ugly)\n",
    "        if xgrid:\n",
    "            last_axis.tick_params(axis='both', which='both',length=0)\n",
    "    else:\n",
    "        last_axis.xaxis.set_visible(False)\n",
    "\n",
    "    last_axis.yaxis.set_visible(False)\n",
    "    last_axis.grid(xgrid)\n",
    "\n",
    "\n",
    "    # Last axis on the back\n",
    "    last_axis.zorder = min(a.zorder for a in _axes) - 1\n",
    "    _axes = list(_axes) + [last_axis]\n",
    "\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "\n",
    "\n",
    "    # The magic overlap happens here.\n",
    "    h_pad = 10 + (- 6*(1 + overlap))\n",
    "    fig.tight_layout(h_pad=h_pad)\n",
    "\n",
    "\n",
    "    return fig, _axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BONUS - Joyplots (Density plots of Tumor Volumes for the most promising treatments)\n",
    "# NOTE:  Joyplot function is not the work of this student. It is a free-to-use function.\n",
    "%matplotlib inline\n",
    "\n",
    "fig, axes = joyplot(df)\n",
    "\n",
    "a = axes[-1]\n",
    "xticks = a.get_xticks()\n",
    "a.set_xticks(np.arange(xticks.min(), xticks.max()+5, 5))\n",
    "plt.title(\"Final Tumor Volume for Treatments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a box plot of the final tumor volume of each mouse across four regimens of interest\n",
    "#note that 'Placebo' comparison is a must (control). We sort by tumor final volume to obtain the best treatment outcome.\n",
    "df['Group'] = 'Treatment Final Tumor vol'\n",
    "\n",
    "\n",
    "\n",
    "df.groupby('Group').boxplot()\n",
    "plt.ylabel('Tumor Vol mm^3')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ramicane_filter = cleaned_df[cleaned_df['Drug Regimen'].isin(['Ramicane'])]\n",
    "\n",
    "filter_df=cleaned_df[cleaned_df['Drug Regimen'].isin(['Ramicane', 'Capomulin','Ceftamin','Infubinol'])]\n",
    "print(filter_df)\n",
    "filter_df.boxplot(by='Drug Regimen', \n",
    "                       column=['Tumor Volume (mm3)'], \n",
    "                       grid=True)\n",
    "plt.ylabel('Tumor Vol mm^3')\n",
    "plt.title('')\n",
    "#cleaned_df.boxplot(by='Drug Regimen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line and Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a line plot of time point versus tumor volume for a mouse treated with Capomulin\n",
    "# get how many time points are unique\n",
    "timepts = drop_dup_df[\"Timepoint\"].nunique()\n",
    "drug_reg_df = drop_dup_df.groupby(\"Drug Regimen\")\n",
    "#print(drug_reg_df.head())\n",
    "Capomulin = drop_dup_df[drop_dup_df['Drug Regimen']=='Capomulin']\n",
    "\n",
    "df_plot_scatter = Capomulin.head(timepts)\n",
    "\n",
    "mouse = df_plot_scatter.iloc[0, 0]\n",
    "\n",
    "plt.scatter(df_plot_scatter['Timepoint'], df_plot_scatter['Tumor Volume (mm3)'])\n",
    "#plt.title('Tumor Vol vs Timepoint for mouse:',mouse)\n",
    "plt.xlabel(\"Timepoint\")\n",
    "plt.ylabel(\"Tumor vol mm^3\")\n",
    "plt.title(\"Tumor Vol vs Timepoint (Capomulin) for Mouse: \"+ mouse)\n",
    "\n",
    "x = np.array(df_plot_scatter['Timepoint'])\n",
    "y = np.array(df_plot_scatter['Tumor Volume (mm3)'])\n",
    "(slope, intercept, rvalue, pvalue, stderr) = linregress(x, y)\n",
    "regress_values = x * slope + intercept\n",
    "rvalue = round(rvalue,2)\n",
    "rsqr = round(rvalue**2,2)\n",
    "rstring = str(rsqr)\n",
    "rstring = 'R-sqr= '+ rstring\n",
    "print (rvalue)\n",
    "line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x,regress_values,\"r-\")\n",
    "plt.annotate(line_eq,(0,30),fontsize=10,color=\"black\")\n",
    "plt.annotate(rstring,(0,28),fontsize=10,color=\"black\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation and Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a scatter plot of mouse weight versus average tumor volume for the Capomulin regimen\n",
    "# Get x and y for plot\n",
    "\n",
    "x = np.array(Capomulin['Weight (g)'])\n",
    "y = np.array(Capomulin['Tumor Volume (mm3)'])\n",
    "plt.xlabel(\"Mouse Weight (g)\")\n",
    "plt.ylabel(\"Tumor vol mm^3\")\n",
    "plt.title(\"Tumor Vol vs Mouse Weight(g) for (Capomulin)\")\n",
    "(slope, intercept, rvalue, pvalue, stderr) = linregress(x, y)\n",
    "regress_values = x * slope + intercept\n",
    "rvalue = round(rvalue,2)\n",
    "\n",
    "rsqr = round(rvalue**2,2)\n",
    "line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
    "rstring= 'r-sqr =' + str(rsqr)\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x,regress_values,\"r-\")\n",
    "plt.annotate(line_eq,(20,30),fontsize=10,color=\"black\")\n",
    "plt.annotate(rstring,(20,28),fontsize=10,color=\"black\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation and Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We know that the Tumor volumes are not normally distributed, but for fun\n",
    "#let's run a multiple linear regression using OLS method to see if tumor volumes are impacted by other factors\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "ramificane_filter = ramicane_filter.drop(['Timepoint', 'Metastatic Sites','Mouse ID','Drug Regimen'], axis=1)\n",
    "df_sex = ramicane_filter.drop(['Weight (g)', 'Age_months','Tumor Volume (mm3)'], axis=1)\n",
    "\n",
    "lb_make = LabelEncoder()\n",
    "df_code[\"sex_code\"] = lb_make.fit_transform(ramificane_filter[\"Sex\"])\n",
    "df_code[[\"Sex\", \"sex_code\"]].head(11)\n",
    "ramificane_filter['sex']=df_code[\"sex_code\"]\n",
    "print(ramificane_filter)\n",
    "X = ramificane_filter[['sex','Age_months','Weight (g)']] # here we have 2 variables for multiple regression. If you just want to use one variable for simple linear regression, then use X = df['Interest_Rate'] for example.Alternatively, you may add additional variables within the brackets\n",
    "Y = ramificane_filter['Tumor Volume (mm3)']\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "model = sm.OLS(Y, X).fit()\n",
    "predictions = model.predict(X) \n",
    " \n",
    "print_model = model.summary()\n",
    "print(print_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
